{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashion_mnist.utils.mnist_reader import load_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('fashion_mnist/data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('fashion_mnist/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci√≥n del dataset fashion Mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualmente, una observacion del dataset representa a una imagen perteneciente a una de las 10 clases de ropa que contiene el mismo.\n",
    "### Clases de ropa\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,3)\n",
    "s = 28\n",
    "for i in range(len(axes)):\n",
    "    #print(ax)\n",
    "    tmpX = np.array(X_train[s])\n",
    "    tmpX = tmpX.reshape(28,28)  # ya que las observaciones estan flattened\n",
    "    axes[i].imshow(tmpX, interpolation='nearest', cmap='gray')\n",
    "    s+=30\n",
    "#ax[1].imshow(X, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen consiste en 784 (28*28) features, en donde cada una de estas pertenece al dominio de [0-255], siendo este la intensidad de brillo para cada pixel. 0 representa el color negro, y conforme se acerque a 255, m√°s brillante ser√° el pixel (m√°s blanco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# una sola observacion del dataset, tiene 784 features que corresponden a los pixeles de la imagen.\n",
    "X_train[28].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[28] # la observacion numero 28, corresponde a la clase 4, es decir, a la clase de chaqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparaci√≥n del dataset para poder procesarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mis algoritmos procesan los datos con la siguiente estructura:\n",
    "* Cada fila del dataset, representa una feature, y cada columna el valor de dicha feature para cada imagen.\n",
    "* La estructura del shape debe ser (n_features, n_observaciones)\n",
    "\n",
    "El dataset contiene la siguiente estructura:\n",
    "* Cada fila, es una imagen, y esta contiene los valores de las 784 features para dicha imagen.\n",
    "* Por lo tanto, la estructura del shape es (n_observaciones, n_features)\n",
    "\n",
    "Por este motivo se procede a transponer la matriz de X para ajustarla a la estructura que maneja mis algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El dataset viene con estructura \n",
    "# 60000 imagenes, 784 features\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 784 features, con su respectivo valor para las 60000 imagenes.\n",
    "X_train_t = X_train.T\n",
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera, es necesario transformar la clase a predecir, ya que esta consiste en 60000 valores que se√±alan la clase a la que pertenece la imagen. Cuando se necesita que tenga la siguiente estructura:\n",
    "* Cada columna, indica la clase a la que pertencen las observaciones siendo cada columna mutuamente excluyente.\n",
    "* Cada fila, es una de las 10 clases\n",
    "\n",
    "Por lo tanto, convertir√© los 60000 valores a arreglos en donde la posici√≥n del valor 1 exprese la clase a la que corresponde.\n",
    "* Estructura a alcanzar (n_clases, n_observaciones)\n",
    "* Estructura actual (n_observaciones,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_t = (y_train.reshape(y_train.shape[0], 1) == np.arange(10)).astype(int).transpose()\n",
    "Y_train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La interpretacion de esta nueva matriz de Y es la siguiente:\n",
    "* Cada columna indica a que clase pertenece una imagen.\n",
    "\n",
    "Por ejemplo: \n",
    "* La primera columna, que corresponde a la primera observacion, el 1 se encuentra en la fila 10, por lo tanto pertence a la clase 9 (10-1), siendo esta la clase de Botas.\n",
    "* La segunda columna, que corresponde a la segunda observacion, el 1 se encuentra en la fila 1, por lo tanto pertence a la clase 0 (1-1), siendo esta la clase de T-shirt.\n",
    "\n",
    "A continuacion se comprueban ambos ejemplos visualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La primera observacion corresponde a una bota, tal y como se interpreta de la matriz de Ys\n",
    "fig, ax = plt.subplots()\n",
    "tmpX = np.array(X_train[0])\n",
    "tmpX = tmpX.reshape(28,28)  # ya que las observaciones estan flattened\n",
    "ax.imshow(tmpX, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La segunda observacion corresponde a la clase 0, es decir, a una tshirt, tal y como se interpreta de la matriz de Ys\n",
    "fig, ax = plt.subplots()\n",
    "tmpX = np.array(X_train[1])\n",
    "tmpX = tmpX.reshape(28,28)  # ya que las observaciones estan flattened\n",
    "ax.imshow(tmpX, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos a utilizar para Feed Forward Multi-Class Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fx para aplanar matrices de tetas, ya que asi lo solicita optimize\n",
    "flattenize_tetas = lambda tetas_matrixes : np.concatenate(\n",
    "    [\n",
    "        tetas_matrixes[i].flatten()\n",
    "        for i in range(len(tetas_matrixes))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tetas_matrix(flat_tetas_array, nn_arch):\n",
    "    \"\"\" Transformo un arreglo unidimensional de tetas, en un arreglo de matrices de tetas.\n",
    "    \n",
    "    flat_tetas_array: array unidimensional con los valores de tetas.\n",
    "    nn_arch: Architectura de la red neuronal, es un arreglo con la cantidad de neuronas en cada capa.\n",
    "    \n",
    "    Retorno un arreglo de matrices de tetas con sus correspondientes shapes.\n",
    "    \"\"\"\n",
    "    layers = len(nn_arch)\n",
    "    \n",
    "    # construyo los shapes utilizando la arquitectura de la Red Neuronal.\n",
    "    # Shape = (Cantidad neuronas de salida, Cantidad neuronas entrada + 1) por el bias \n",
    "    shapes = [\n",
    "        (\n",
    "            nn_arch[i+1], # neuronas de salida en la sig. capa\n",
    "            nn_arch[i]+1 # neuronas de entrada mas neurona del bias\n",
    "        ) for i in range(layers - 1)\n",
    "    ]\n",
    "    \n",
    "    # Calculo el espacio en indices que cada matriz ocupa en el arreglo\n",
    "    block_size = [\n",
    "        np.product(shape)\n",
    "        for shape in shapes\n",
    "    ]\n",
    "    \n",
    "    accum_block_size = np.zeros(layers, dtype=int) # indices para cada particion del flat array\n",
    "    \n",
    "    for i in range(len(block_size)):\n",
    "        accum_block_size[i+1] = accum_block_size[i] + block_size[i] # Calculo la suma acumulada de los indices\n",
    "    \n",
    "    return [\n",
    "        flat_tetas_array[\n",
    "            accum_block_size[i] : accum_block_size[i+1]\n",
    "        ].reshape(*shapes[i]) # reshapeo cada segmento del flat array a su shape correspondiente\n",
    "        for i in range(len(shapes))\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para agregar la fila de bias.\n",
    "def transformar_bias(x_set, grado):\n",
    "    \n",
    "    unos = np.ones(x_set.shape[1]) # [1] ya que X viene en formato de filas, por lo que cada columna es una observacion.\n",
    "    \n",
    "    if grado == 1:\n",
    "        X = np.vstack(\n",
    "            (\n",
    "            unos,\n",
    "            x_set,\n",
    "            #-x_set**2\n",
    "            )\n",
    "        ).T # Se transpuso la matriz para tener la columna de unos y asi calcular teta_0\n",
    "    elif grado == 2:\n",
    "        X = np.vstack(\n",
    "            (\n",
    "            unos,\n",
    "            x_set,\n",
    "            x_set**2\n",
    "            )\n",
    "        ).T\n",
    "    elif grado == -2:\n",
    "        X = np.vstack(\n",
    "            (\n",
    "            unos,\n",
    "            x_set,\n",
    "            -x_set**2\n",
    "            )\n",
    "        ).T\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion de activacion sigmoide\n",
    "def h_teta(matriz_t, matriz_x): # esta funcion es sigmoide(h_zeta)\n",
    "    zeta_teta = np.matmul(\n",
    "        matriz_t,\n",
    "        transformar_bias(matriz_x,1).T\n",
    "    )\n",
    "    #print('Zeta teta: ', zeta_teta) # si zeta >= 0; entonces clase positiva.\n",
    "    #[5,4,-1] = 5 + 4x1-x2 = 0\n",
    "    # x2 =  5 + 4x1\n",
    "    return ((1 + np.power(np.e, -1*zeta_teta))**-1) # (n,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jota_teta(T, nn_arch, X, Y):\n",
    "    A = feed_forward(\n",
    "        build_tetas_matrix(T, nn_arch),\n",
    "        X\n",
    "    )\n",
    "    m = X.shape[1]\n",
    "    #print('Prediccion ', A[-1])\n",
    "    #print('Producto ', np.multiply(Y, np.log(A[-1])))\n",
    "    #print('Producto 2 ', np.multiply((1-Y),np.log(1 - A[-1])))\n",
    "\n",
    "    return -(Y.T * np.log(A[-1].T) + (1 - Y.T)*np.log(1 - A[-1].T)).sum() / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-341-5b94d6b71568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m -(\n\u001b[0;32m      2\u001b[0m         np.sum(\n\u001b[1;32m----> 3\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     ) / m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "-(\n",
    "        np.sum(\n",
    "            np.multiply(Y, np.log(A[-1])) +\n",
    "            np.multiply((1-Y),np.log(1 - A[-1]))\n",
    "    ) / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(T, X):\n",
    "    \"\"\" Calcula un arreglo de vectores con los valores de activaci√≥n de cada capa.\"\"\"\n",
    "    # X no tiene que entrar con bias.\n",
    "    A = [X] # a0 = z0 El vector de activacion en la capa 0 es igual al vector de entradas\n",
    "\n",
    "    for i in range(len(T)):\n",
    "        A.append(\n",
    "            # h_teta es la fx de activacion; sigmoide.\n",
    "            h_teta(\n",
    "                T[i],\n",
    "                A[i] # en h_teta le agrego el bias a la matriz de activaciones\n",
    "            )\n",
    "        )\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(T, nn_arch, X, Y):\n",
    "    \"\"\"Calculo la matriz del gradiente para las tetas de cada capa de la Red Neuronal.\n",
    "    \n",
    "    T: Arrgelo flat de todas las tetas de la Red Neuronal.\n",
    "    nn_arch: Arreglo de la cantidad de neuronas por capa, incluye capa de entrada y salida.\n",
    "    \n",
    "    Retorno el gradiente para cada capa\n",
    "    \"\"\"\n",
    "    #Paso 1\n",
    "    \n",
    "    m = X.shape[1] # [1] porque cada columna es una observacion.\n",
    "    layers = len(nn_arch)\n",
    "    TETAS = build_tetas_matrix(T, nn_arch)\n",
    "    \n",
    "    D = [0.0 for teta in TETAS] # Gradiente para las tetas de cada capa de transicion.\n",
    "    #print('Len tetas builded: ', len(TETAS))\n",
    "    \n",
    "    # Paso 2.2\n",
    "    A = feed_forward(TETAS, X) # valores de activacion para cada neurona de cada capa\n",
    "    \n",
    "    # Calculo el error entre la hipotesis de la NN y los valores actuales.\n",
    "    d = [*range(layers - 1), A[-1] - Y] # -1 porque no tomo en cuenta la primera capa\n",
    "    \n",
    "    for l in range(layers-2, -1, -1): # -2 por capa de salida ya calculada, y capa de entrada. Solo para transitions.\n",
    "        #print('Shape TETAS[l][:,1:] ', TETAS[l][:, 1:].T.shape)\n",
    "        #print('Shape Delta[l+1] ', D[l+1].shape)\n",
    "        #print('Shape A[l] ', A[l].shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        # Paso 2.4\n",
    "        d[l] = np.matmul(\n",
    "            TETAS[l][:, 1:].T, # (3, 3) Excluyo la neurona del bias.\n",
    "            d[l+1] # (3, m) cantidad de neuronas, m -> cantidad obs.\n",
    "        ) * A[l] * (1 - A[l])\n",
    "        \n",
    "        # Paso 2.5 y 2.6\n",
    "        D[l] += np.matmul(\n",
    "            d[l+1], # diferencia capa siguiente (3,5)\n",
    "            np.vstack((np.ones((1,m), float), A[l])).T # (5,4) valores de las neuronas en capa de activacion \n",
    "        )\n",
    "    print('Pred capa salida ', d[layers-1].shape)\n",
    "    return flattenize_tetas(np.divide(D, m)) # Paso 3, retorno la matriz de gradientes flattened\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizaci√≥n de inputs de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla de aleatoriedad para replicar el analisis.\n",
    "np.random.seed(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 60000), (10, 60000))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape, Y_train_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los valores de X presentan un dominio de [0-255], las operaciones matriciales pueden aumentar la complejidad computacional en los casos donde los valores son muy grandes, por lo que se proceder√° a normalizar tales valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIO = 1 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   0,   0,  13,  73,   0,   0,   1,\n",
       "         4,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   3,   0,  36, 136, 127,  62,\n",
       "        54,   0,   0,   0,   1,   3,   4,   0,   0,   3,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0, 102, 204,\n",
       "       176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,\n",
       "        15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         0,  69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,\n",
       "        88, 172,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         1,   1,   0, 200, 232, 232, 233, 229, 223, 223, 215, 213, 164,\n",
       "       127, 123, 196, 229,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 183, 225, 216, 223, 228, 235, 227, 224,\n",
       "       222, 224, 221, 223, 245, 173,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 193, 228, 218, 213, 198, 180,\n",
       "       212, 210, 211, 213, 223, 220, 243, 202,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   3,   0,  12, 219, 220, 212, 218,\n",
       "       192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244, 222,\n",
       "       220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "       236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "        92,   0,   0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,\n",
       "         0, 237, 226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215,\n",
       "       218, 255,  77,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "        62, 145, 204, 228, 207, 213, 221, 218, 208, 211, 218, 224, 223,\n",
       "       219, 215, 224, 244, 159,   0,   0,   0,   0,   0,  18,  44,  82,\n",
       "       107, 189, 228, 220, 222, 217, 226, 200, 205, 211, 230, 224, 234,\n",
       "       176, 188, 250, 248, 233, 238, 215,   0,   0,  57, 187, 208, 224,\n",
       "       221, 224, 208, 204, 214, 208, 209, 200, 159, 245, 193, 206, 223,\n",
       "       255, 255, 221, 234, 221, 211, 220, 232, 246,   0,   3, 202, 228,\n",
       "       224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80, 150, 255,\n",
       "       229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0,  98,\n",
       "       233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
       "        65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,\n",
       "        29,  75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206,\n",
       "       198, 213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220,\n",
       "       221, 230,  67,  48, 203, 183, 194, 213, 197, 185, 190, 194, 192,\n",
       "       202, 214, 219, 221, 220, 236, 225, 216, 199, 206, 186, 181, 177,\n",
       "       172, 181, 205, 206, 115,   0, 122, 219, 193, 179, 171, 183, 196,\n",
       "       204, 210, 213, 207, 211, 210, 200, 196, 194, 191, 195, 191, 198,\n",
       "       192, 176, 156, 167, 177, 210,  92,   0,   0,  74, 189, 212, 191,\n",
       "       175, 172, 175, 181, 185, 188, 189, 188, 193, 198, 204, 209, 210,\n",
       "       210, 211, 188, 188, 194, 192, 216, 170,   0,   2,   0,   0,   0,\n",
       "        66, 200, 222, 237, 239, 242, 246, 243, 244, 221, 220, 193, 191,\n",
       "       179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
       "       0.28627451, 0.        , 0.        , 0.00392157, 0.01568627,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.14117647, 0.53333333, 0.49803922, 0.24313725,\n",
       "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01176471, 0.01568627, 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "       0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.60784314, 0.9254902 , 0.81176471,\n",
       "       0.69803922, 0.41960784, 0.61176471, 0.63137255, 0.42745098,\n",
       "       0.25098039, 0.09019608, 0.30196078, 0.50980392, 0.28235294,\n",
       "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.27058824,\n",
       "       0.81176471, 0.8745098 , 0.85490196, 0.84705882, 0.84705882,\n",
       "       0.63921569, 0.49803922, 0.4745098 , 0.47843137, 0.57254902,\n",
       "       0.55294118, 0.34509804, 0.6745098 , 0.25882353, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.        , 0.78431373, 0.90980392, 0.90980392,\n",
       "       0.91372549, 0.89803922, 0.8745098 , 0.8745098 , 0.84313725,\n",
       "       0.83529412, 0.64313725, 0.49803922, 0.48235294, 0.76862745,\n",
       "       0.89803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.71764706, 0.88235294, 0.84705882, 0.8745098 , 0.89411765,\n",
       "       0.92156863, 0.89019608, 0.87843137, 0.87058824, 0.87843137,\n",
       "       0.86666667, 0.8745098 , 0.96078431, 0.67843137, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "       0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "       0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "       0.95294118, 0.79215686, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
       "       0.04705882, 0.85882353, 0.8627451 , 0.83137255, 0.85490196,\n",
       "       0.75294118, 0.6627451 , 0.89019608, 0.81568627, 0.85490196,\n",
       "       0.87843137, 0.83137255, 0.88627451, 0.77254902, 0.81960784,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02352941, 0.        , 0.38823529, 0.95686275,\n",
       "       0.87058824, 0.8627451 , 0.85490196, 0.79607843, 0.77647059,\n",
       "       0.86666667, 0.84313725, 0.83529412, 0.87058824, 0.8627451 ,\n",
       "       0.96078431, 0.46666667, 0.65490196, 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568627, 0.        ,\n",
       "       0.        , 0.21568627, 0.9254902 , 0.89411765, 0.90196078,\n",
       "       0.89411765, 0.94117647, 0.90980392, 0.83529412, 0.85490196,\n",
       "       0.8745098 , 0.91764706, 0.85098039, 0.85098039, 0.81960784,\n",
       "       0.36078431, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01568627, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.92941176,\n",
       "       0.88627451, 0.85098039, 0.8745098 , 0.87058824, 0.85882353,\n",
       "       0.87058824, 0.86666667, 0.84705882, 0.8745098 , 0.89803922,\n",
       "       0.84313725, 0.85490196, 1.        , 0.30196078, 0.        ,\n",
       "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "       0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "       0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "       0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "       0.95686275, 0.62352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156863,\n",
       "       0.41960784, 0.74117647, 0.89411765, 0.8627451 , 0.87058824,\n",
       "       0.85098039, 0.88627451, 0.78431373, 0.80392157, 0.82745098,\n",
       "       0.90196078, 0.87843137, 0.91764706, 0.69019608, 0.7372549 ,\n",
       "       0.98039216, 0.97254902, 0.91372549, 0.93333333, 0.84313725,\n",
       "       0.        , 0.        , 0.22352941, 0.73333333, 0.81568627,\n",
       "       0.87843137, 0.86666667, 0.87843137, 0.81568627, 0.8       ,\n",
       "       0.83921569, 0.81568627, 0.81960784, 0.78431373, 0.62352941,\n",
       "       0.96078431, 0.75686275, 0.80784314, 0.8745098 , 1.        ,\n",
       "       1.        , 0.86666667, 0.91764706, 0.86666667, 0.82745098,\n",
       "       0.8627451 , 0.90980392, 0.96470588, 0.        , 0.01176471,\n",
       "       0.79215686, 0.89411765, 0.87843137, 0.86666667, 0.82745098,\n",
       "       0.82745098, 0.83921569, 0.80392157, 0.80392157, 0.80392157,\n",
       "       0.8627451 , 0.94117647, 0.31372549, 0.58823529, 1.        ,\n",
       "       0.89803922, 0.86666667, 0.7372549 , 0.60392157, 0.74901961,\n",
       "       0.82352941, 0.8       , 0.81960784, 0.87058824, 0.89411765,\n",
       "       0.88235294, 0.        , 0.38431373, 0.91372549, 0.77647059,\n",
       "       0.82352941, 0.87058824, 0.89803922, 0.89803922, 0.91764706,\n",
       "       0.97647059, 0.8627451 , 0.76078431, 0.84313725, 0.85098039,\n",
       "       0.94509804, 0.25490196, 0.28627451, 0.41568627, 0.45882353,\n",
       "       0.65882353, 0.85882353, 0.86666667, 0.84313725, 0.85098039,\n",
       "       0.8745098 , 0.8745098 , 0.87843137, 0.89803922, 0.11372549,\n",
       "       0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "       0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "       0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "       0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "       0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "       0.86666667, 0.90196078, 0.2627451 , 0.18823529, 0.79607843,\n",
       "       0.71764706, 0.76078431, 0.83529412, 0.77254902, 0.7254902 ,\n",
       "       0.74509804, 0.76078431, 0.75294118, 0.79215686, 0.83921569,\n",
       "       0.85882353, 0.86666667, 0.8627451 , 0.9254902 , 0.88235294,\n",
       "       0.84705882, 0.78039216, 0.80784314, 0.72941176, 0.70980392,\n",
       "       0.69411765, 0.6745098 , 0.70980392, 0.80392157, 0.80784314,\n",
       "       0.45098039, 0.        , 0.47843137, 0.85882353, 0.75686275,\n",
       "       0.70196078, 0.67058824, 0.71764706, 0.76862745, 0.8       ,\n",
       "       0.82352941, 0.83529412, 0.81176471, 0.82745098, 0.82352941,\n",
       "       0.78431373, 0.76862745, 0.76078431, 0.74901961, 0.76470588,\n",
       "       0.74901961, 0.77647059, 0.75294118, 0.69019608, 0.61176471,\n",
       "       0.65490196, 0.69411765, 0.82352941, 0.36078431, 0.        ,\n",
       "       0.        , 0.29019608, 0.74117647, 0.83137255, 0.74901961,\n",
       "       0.68627451, 0.6745098 , 0.68627451, 0.70980392, 0.7254902 ,\n",
       "       0.7372549 , 0.74117647, 0.7372549 , 0.75686275, 0.77647059,\n",
       "       0.8       , 0.81960784, 0.82352941, 0.82352941, 0.82745098,\n",
       "       0.7372549 , 0.7372549 , 0.76078431, 0.75294118, 0.84705882,\n",
       "       0.66666667, 0.        , 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.25882353, 0.78431373, 0.87058824, 0.92941176,\n",
       "       0.9372549 , 0.94901961, 0.96470588, 0.95294118, 0.95686275,\n",
       "       0.86666667, 0.8627451 , 0.75686275, 0.74901961, 0.70196078,\n",
       "       0.71372549, 0.71372549, 0.70980392, 0.69019608, 0.65098039,\n",
       "       0.65882353, 0.38823529, 0.22745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "       0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train_t * RATIO\n",
    "X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquitectura NN:  [784, 130, 10]\n"
     ]
    }
   ],
   "source": [
    "NN_ARCH = [\n",
    "    X_train_t.shape[0], # Tendre 784 neuronas de entrada, una para cada feature.\n",
    "    # Capas intermedias\n",
    "    130,\n",
    "    # Neuronas de salida\n",
    "    Y_train_t.shape[0] # Una neurona para cada clase, en total, 10 neuronas de salida\n",
    "]\n",
    "print('Arquitectura NN: ', NN_ARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_HIDDEN_LAYERS = len(NN_ARCH) - 2\n",
    "NN_HIDDEN_LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2130, 785), (10, 2131)]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cada matriz de transicion tendr√° las siguientes shapes\n",
    "[\n",
    "    (\n",
    "        NN_ARCH[i+1], # Cantidad de neuronas de salida\n",
    "        NN_ARCH[i]+1 # Cantidad de neuronas de entrada, mas neurona de bias\n",
    "    )\n",
    "    for i in range(len(NN_ARCH)-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36500686, 0.00833212, 0.66754382, ..., 0.70897968, 0.95737579,\n",
       "       0.26647937])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TETAS INICIALES\n",
    "TETAS = flattenize_tetas([\n",
    "    np.random.rand(\n",
    "        NN_ARCH[i+1], # cantidad de neuronas en siguiente capa.\n",
    "        NN_ARCH[i]+1 # cantidad de neuronas de entrada, + 1 por la neurona del bias\n",
    "    ) for i in range(len(NN_ARCH)-1) # No considero la √∫ltima capa, porque es la hipotesis.\n",
    "])\n",
    "TETAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred capa salida  (10, 60000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.58212356e-08, 0.00000000e+00, 4.06940716e-17, ...,\n",
       "       8.99999979e-01, 8.99999993e-01, 8.99999976e-01])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_propagation(TETAS, NN_ARCH,X, Y_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([[0,0,0,0,1,0],\n",
    "          [0,0,0,0,1,0]]\n",
    "        ) * np.array(\n",
    "    [[0,0,0,0,1,0],\n",
    "     [1,0,0,0,0,0]])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([[0,0,0,0,1,0],\n",
    "          [0,0,0,0,1,0]]\n",
    "        ) == np.array(\n",
    "    [[0,0,0,0,1,0],\n",
    "     [1,0,0,0,0,0]]))* 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\geord\\docs\\2020\\elements\\repo elements-ml\\regresion_logistica\\venv\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "d:\\geord\\docs\\2020\\elements\\repo elements-ml\\regresion_logistica\\venv\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in multiply\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n",
      "Pred capa salida  (10, 60000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.34400486946106"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = op.minimize(\n",
    "    fun=jota_teta,\n",
    "    x0=TETAS,\n",
    "    args=(NN_ARCH, X, Y_train_t),\n",
    "    method='L-BFGS-B',\n",
    "    jac=back_propagation,\n",
    "    options={'disp': True, 'maxiter': 1300})\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3.2508297362261156\n",
       " hess_inv: <103360x103360 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([3.42515374e-09, 0.00000000e+00, 8.72121884e-19, ...,\n",
       "       7.06170289e-07, 7.07616028e-07, 7.05943104e-07])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 24\n",
       "      nit: 13\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.36500682,  0.00833212,  0.66754382, ...,  0.16937952,\n",
       "        0.41777562, -0.27312078])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con 130 neuronas en la capa intermedia\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3.2508297339282053\n",
       " hess_inv: <1693360x1693360 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-5.48957602e-15,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "       -6.23304309e-08, -6.23304225e-08, -6.23304218e-08])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 44\n",
       "      nit: 22\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.00865902,  0.31517236,  0.6917445 , ..., -0.40390914,\n",
       "        0.14517065, -0.33449626])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con mas neuronas (2130)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.55805110931396"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103360,)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x.shape # tetas flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2508297362261156"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Costo\n",
    "jota_teta(res.x, NN_ARCH, X, Y_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = feed_forward(build_tetas_matrix(res.x, NN_ARCH), X)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predicted > .5)*1).sum() # no predice bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intent√© identificar la raz√≥n por la que la red neuronal no predice bien, sin embargo, no me fue posible hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
